import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
from sklearn import datasets,model_selection,linear_model,metrics,decomposition
import seaborn as sns

df = pd.read_csv("UF_R3_ANALYSIS_LASTMAJOR0714BE.csv")

df.dtypes
df.isnull().sum()
df.dropna(axis=0, how='any',inplace=True)
df['STUDENT_SUCCESSNO'].value_counts()
 
 
Categorical variables：


cat = df[["JUNIOR_SENIOR_FLAGNO",
"ENRL_CNT",
"MAJORCOUNT",
"UF_CLASSNO",
"RESIDENCYNO",
"TERM_END_DT_SID_CATGRYNO",
"TERM_BEG_DT_CATGRYNO",
"LOW_TERM_GPA_IND",
"PARTTIME_TERM_IND",
"NOT_REG_TERM_IND",
"WITHDRWL_TERM_IND",
"FULLTIME_TERM_IND",
"OVR_12HR_TERM_IND"]]
corcat = cat.corr(method='kendall')
f, ax = plt.subplots(figsize=(15,15))
sns.heatmap(corcat, vmax=.8, annot=True, square=True)
plt.show()

con = df[[
"TERM_SID",
"TERM_BEG_DT_SID",
"TERM_END_DT_SID",
"AGE_YEARS",
"AGE_MONTHS",
"AGE_DAYS",
"TOT_TRNSFR",
"TOT_TEST_CREDIT",
"UNT_TAKEN_PRGRSS",
"CUM_GPA",
"TOT_TAKEN_GPA",
“UNT_TAKEN_GPA”
]]corcon = con.corr(method='pearson')
f, ax = plt.subplots(figsize=(15,15))
sns.heatmap(corcon, vmax=.8, annot=True, square=True)
plt.show()

Create Two Variables: 'NOT_GRADUATED','GRADUATED_IN_4':
df['NOT_GRADUATED']=df['STUDENT_SUCCESSNO']
df['GRADUATED_IN_4']=df['STUDENT_SUCCESSNO']
df['NOT_GRADUATED'].loc[df['NOT_GRADUATED'] !=1]=0
df['GRADUATED_IN_4'].loc[df['GRADUATED_IN_4'] !=2]=0
df['GRADUATED_IN_4'].loc[df['GRADUATED_IN_4'] ==2]=1



 
Draw the heatmap using seaborn
 
Categorical variables：
 
import seaborn as sns
cat = df[["JUNIOR_SENIOR_FLAGNO",
"ENRL_CNT",
"MAJORCOUNT",
"UF_CLASSNO",
"RESIDENCYNO",
"TERM_END_DT_SID_CATGRYNO",
"TERM_BEG_DT_CATGRYNO",
"LOW_TERM_GPA_IND",
"PARTTIME_TERM_IND",
"NOT_REG_TERM_IND",
"WITHDRWL_TERM_IND",
"FULLTIME_TERM_IND",
"OVR_12HR_TERM_IND"]]
corcat = cat.corr(method='kendall')
f, ax = plt.subplots(figsize=(15,15))
sns.heatmap(corcat, vmax=.8, annot=True, square=True)
plt.show()
 


Correlation Matrix for Models

Continuous variables：
 
con = df[[
"TERM_SID",
"TERM_BEG_DT_SID",
"TERM_END_DT_SID",
"AGE_YEARS",
"AGE_MONTHS",
"AGE_DAYS",
"TOT_TRNSFR",
"TOT_TEST_CREDIT",
"UNT_TAKEN_PRGRSS",
"CUM_GPA",
"TOT_TAKEN_GPA",
“UNT_TAKEN_GPA”
]]corcon = con.corr(method='pearson')
f, ax = plt.subplots(figsize=(15,15))
sns.heatmap(corcon, vmax=.8, annot=True, square=True)
plt.show()


According to the plot above, we can delete the variable “TERM_END_DT_SID”, “TERM_SID” and “UNT_TAKEN_GPA”, and add “GRADUATED_WITHIN_4”.
 
df.loc[df['STUDENT_SUCCESSNO'] !=1]=2
df['GRADUATED_WITHIN_4']=df['STUDENT_SUCCESSNO']

con = df[[
TERM_BEG_DT_SID
"AGE_YEARS",
"AGE_MONTHS",
"AGE_DAYS",
"TOT_TRNSFR",
"TOT_TEST_CREDIT",
"UNT_TAKEN_PRGRSS",
"CUM_GPA",
"TOT_TAKEN_GPA",
“GRADUATED_WITHIN_4”
]]











from sklearn.model_selection import train_test_split
Y = df['STUDENT_SUCCESSNO']
X = df.drop(['STUDENT_SUCCESSNO', 'TERM_END_DT_SID','TERM_SID','UNT_TAKEN_GPA'], axis= 1)
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1234)
 
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
RF = RandomForestClassifier()
RF = RF.fit(x_train, y_train)
y_pred = RF.predict(x_test)
print (metrics.classification_report(y_test, y_pred))
Y_score = RF.predict_proba(x_test)[:,1]

from sklearn.metrics import confusion_matrix
confusion_matrix(y_test, y_pred)


from sklearn.neighbors import KNeighborsClassifier as kNN
model = kNN(n_neighbors = 3, algorithm='auto', weights='distance')
model.fit(x_train,y_train)
y_pred = model.predict(x_test)
print('KNN')
print('acc:', accuracy_score(y_test, y_pred))
print('rec:', recall_score(y_test, y_pred))
print('F1:', f1_score(y_test, y_pred))

from sklearn.metrics import confusion_matrix
confusion_matrix(y_test, y_pred)



Cross Validation
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.model_selection import cross_val_score

Y = df['STUDENT_SUCCESSNO']
X = df.drop(['STUDENT_SUCCESSNO'], axis= 1)
RF = RandomForestClassifier()
scores = cross_val_score(RF, X, Y, cv=5)
scores
 

 
 
Cross Validation

from sklearn.metrics import accuracy_score, recall_score, f1_score
from sklearn.neighbors import KNeighborsClassifier as kNN
 
model = kNN(n_neighbors = 3, algorithm='auto', weights='distance')
Y = df['STUDENT_SUCCESSNO']
X = df.drop(['STUDENT_SUCCESSNO'], axis= 1)
scores = cross_val_score(model, X, Y, cv=5)
Scores

Visualization
 
fig = plt.figure(figsize=(20,10))
plt.bar(df['STUDENT_SUCCESSNO'].value_counts().index, df['STUDENT_SUCCESSNO'].value_counts().values)
plt.xticks(df['STUDENT_SUCCESSNO'].value_counts().index,fontsize=15)
plt.show()
 
plt.scatter(X.values[:, 0], X.values[:, 1], c=Y)
plt.show(




 
One-hot encoding
 
df_JUNIOR_SENIOR_FLAGNO = df['JUNIOR_SENIOR_FLAGNO'].apply(str).str.get_dummies().add_prefix('JUNIOR_SENIOR_FLAGNO: ')
df_ENRL_CNT = df['ENRL_CNT'].apply(str).str.get_dummies().add_prefix('ENRL_CNT: ')
df_MAJORCOUNT = df['MAJORCOUNT'].apply(str).str.get_dummies().add_prefix('MAJORCOUNT: ')
df_UF_CLASSNO = df['UF_CLASSNO'].apply(str).str.get_dummies().add_prefix('UF_CLASSNO: ')
df_RESIDENCYNO = df['RESIDENCYNO'].apply(str).str.get_dummies().add_prefix('RESIDENCYNO: ')
df_TERM_END_DT_SID_CATGRYNO = df['TERM_END_DT_SID_CATGRYNO'].apply(str).str.get_dummies().add_prefix('TERM_END_DT_SID_CATGRYNO: ')
df_TERM_BEG_DT_CATGRYNO = df['TERM_BEG_DT_CATGRYNO'].apply(str).str.get_dummies().add_prefix('TERM_BEG_DT_CATGRYNO: ')
df_LOW_TERM_GPA_IND = df['LOW_TERM_GPA_IND'].apply(str).str.get_dummies().add_prefix('LOW_TERM_GPA_IND: ')
df_PARTTIME_TERM_IND = df['PARTTIME_TERM_IND'].apply(str).str.get_dummies().add_prefix('PARTTIME_TERM_IND: ')
df_NOT_REG_TERM_IND = df['NOT_REG_TERM_IND'].apply(str).str.get_dummies().add_prefix('NOT_REG_TERM_IND: ')
df_WITHDRWL_TERM_IND = df['WITHDRWL_TERM_IND'].apply(str).str.get_dummies().add_prefix('WITHDRWL_TERM_IND: ')
df_FULLTIME_TERM_IND = df['FULLTIME_TERM_IND'].apply(str).str.get_dummies().add_prefix('FULLTIME_TERM_IND: ')
df_OVR_12HR_TERM_IND = df['OVR_12HR_TERM_IND'].apply(str).str.get_dummies().add_prefix('OVR_12HR_TERM_IND: ')
df = pd.concat([df,df_JUNIOR_SENIOR_FLAGNO,df_ENRL_CNT,df_MAJORCOUNT,df_UF_CLASSNO,df_RESIDENCYNO,df_TERM_END_DT_SID_CATGRYNO,df_TERM_BEG_DT_CATGRYNO,df_LOW_TERM_GPA_IND,df_PARTTIME_TERM_IND,df_NOT_REG_TERM_IND,df_WITHDRWL_TERM_IND,df_FULLTIME_TERM_IND,df_OVR_12HR_TERM_IND],axis=1)
df = df.drop([
	'JUNIOR_SENIOR_FLAGNO',
 'ENRL_CNT',
 'MAJORCOUNT',
 'UF_CLASSNO',
 'RESIDENCYNO',
 'TERM_END_DT_SID_CATGRYNO',
 'TERM_BEG_DT_CATGRYNO',
 'LOW_TERM_GPA_IND',
 'PARTTIME_TERM_IND',
 'NOT_REG_TERM_IND',
 'WITHDRWL_TERM_IND',
 'FULLTIME_TERM_IND',
 'OVR_12HR_TERM_IND'
],axis=1)
 
Y = df['STUDENT_SUCCESSNO']
X = df.drop(['STUDENT_SUCCESSNO', 'TERM_END_DT_SID','TERM_SID','UNT_TAKEN_GPA'], axis= 1)
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=3234)
 
from sklearn.neighbors import KNeighborsClassifier as kNN
model = kNN(n_neighbors = 3, algorithm='auto', weights='distance')
model.fit(x_train,y_train)
y_pred = model.predict(x_test)
from sklearn.metrics import classification_report, confusion_matrix
print(classification_report(y_test, y_pred))

Heatmap Comparing the Actual Target Values with Predict Target Values

df2=pd.read_csv(“UF_R3_ANALYSIS_LASTMAJOR0714BE.csv")
df2.dropna(axis=0, how='any',inplace=True)
df2 = df2.loc[df2['STUDENT_SUCCESSNO'].isin(['1','2'])]
Y2 = df2['STUDENT_SUCCESSNO']
X2 = df2.drop(['TERM_END_DT_SID','TERM_SID','UNT_TAKEN_GPA'], axis= 1)
x_train2, x_test2, y_train2, y_test2 = train_test_split(X2, Y2, test_size=0.2, random_state=3234)
slen = len(x_test2['STUDENT_SUCCESSNO'])
x_test2.loc[:,'Predict'] = pd.Series(np.random.randn(slen),index = x_test2.index)
x_test2.loc[:,'Predict']=y_pred
import seaborn as sns
heat4 = x_test2[["TOT_TAKEN_GPA",
"ENRL_CNT",
"RESIDENCYNO",
"PARTTIME_TERM_IND",
"NOT_REG_TERM_IND",
"WITHDRWL_TERM_IND",
"FULLTIME_TERM_IND",
"STUDENT_SUCCESSNO",
"Predict"]]
corcon4 = heat4.corr(method='kendall')
f, ax = plt.subplots(figsize=(15,15))
sns.heatmap(corcon4, vmax=.8, annot=True, square=True)
plt.show()

print(x_test2[["STUDENT_SUCCESSNO","Predict"]])





Save model:
from sklearn.externals import joblib
joblib.dump(model, "train_model.m")

Load model:
clf = joblib.load('train_model.m')

Pull 1 sample student who graduated in 4 years:
Sample1=df.iloc[-1:].drop(['STUDENT_SUCCESSNO'], axis= 1)
Pull 1 sample student who did not graduated :
Sample2=df.iloc[-2:-1].drop(['STUDENT_SUCCESSNO'], axis= 1)

Use our model to predict the two students:
Y_pred = model.predict(Sample1)
Y_pred = model.predict(Sample2)
 



















